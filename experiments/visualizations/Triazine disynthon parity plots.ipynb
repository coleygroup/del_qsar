{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import h5py\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELQSAR_ROOT = os.getcwd() + '/../../'\n",
    "sys.path += [DELQSAR_ROOT + '/../']\n",
    "\n",
    "from del_qsar import splitters, models\n",
    "from del_qsar.enrichments import R_ranges\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-paper')\n",
    "\n",
    "matplotlib.rc('font', family='sans-serif')\n",
    "matplotlib.rc('font', serif='Arial')\n",
    "matplotlib.rc('text', usetex='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DD1S_FINGERPRINTS_FILENAME = 'x_DD1S_CAIX_2048_bits_all_fps.h5' # should be in the experiments folder\n",
    "triazine_FINGERPRINTS_FILENAME = 'x_triazine_2048_bits_all_fps.h5' # should be in the experiments folder\n",
    "\n",
    "# CAIX_RANDOM_SPLIT_MODEL_PATH = os.path.join(DELQSAR_ROOT, 'experiments', 'models', 'DD1S_CAIX', \n",
    "#                                           'FP-FFNN', 'random_seed_0.torch')\n",
    "sEH_RANDOM_SPLIT_MODEL_PATH = os.path.join(DELQSAR_ROOT, 'experiments', 'models', 'triazine_sEH', \n",
    "                                          'FP-FFNN', 'random_seed_0.torch')\n",
    "SIRT2_RANDOM_SPLIT_MODEL_PATH = os.path.join(DELQSAR_ROOT, 'experiments', 'models', 'triazine_SIRT2', \n",
    "                                            'FP-FFNN', 'random_seed_0.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = None\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpd_indices(num_cyc1_BBs, num_cyc2_BBs, num_cyc3_BBs):\n",
    "    cpd_indices = []\n",
    "    \n",
    "    for j, k in tqdm(product(range(1, num_cyc2_BBs+1), range(1, num_cyc3_BBs+1))):\n",
    "        cpd_indices.append(np.squeeze(np.where(df_data['cycle2'].isin([j]) & df_data['cycle3'].isin([k]))))\n",
    "    for i, k in tqdm(product(range(1, num_cyc1_BBs+1), range(1, num_cyc3_BBs+1))):\n",
    "        cpd_indices.append(np.squeeze(np.where(df_data['cycle1'].isin([i]) & df_data['cycle3'].isin([k]))))\n",
    "    for i, j in tqdm(product(range(1, num_cyc1_BBs+1), range(1, num_cyc2_BBs+1))):\n",
    "        cpd_indices.append(np.squeeze(np.where(df_data['cycle1'].isin([i]) & df_data['cycle2'].isin([j]))))\n",
    "        \n",
    "    cpd_indices = np.array(cpd_indices)\n",
    "    \n",
    "    return cpd_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_for_disynthons(num_cyc1_BBs, num_cyc2_BBs, num_cyc3_BBs, exp_col_name, beads_col_name):  \n",
    "    disynthon_exp_counts, disynthon_bead_counts = [], []\n",
    "\n",
    "    for j, k in tqdm(product(range(1, num_cyc2_BBs+1), range(1, num_cyc3_BBs+1))):\n",
    "        disynthon_table = df_data[df_data['cycle2'].isin([j]) & df_data['cycle3'].isin([k])]\n",
    "        exp_counts_sum = sum(disynthon_table[exp_col_name])\n",
    "        beads_counts_sum = sum(disynthon_table[beads_col_name])\n",
    "        disynthon_exp_counts.append(exp_counts_sum)\n",
    "        disynthon_bead_counts.append(beads_counts_sum)\n",
    "\n",
    "    for i, k in tqdm(product(range(1, num_cyc1_BBs+1), range(1, num_cyc3_BBs+1))):\n",
    "        disynthon_table = df_data[df_data['cycle1'].isin([i]) & df_data['cycle3'].isin([k])]\n",
    "        exp_counts_sum = sum(disynthon_table[exp_col_name])\n",
    "        beads_counts_sum = sum(disynthon_table[beads_col_name])\n",
    "        disynthon_exp_counts.append(exp_counts_sum)\n",
    "        disynthon_bead_counts.append(beads_counts_sum)\n",
    "\n",
    "    for i, j in tqdm(product(range(1, num_cyc1_BBs+1), range(1, num_cyc2_BBs+1))):\n",
    "        disynthon_table = df_data[df_data['cycle1'].isin([i]) & df_data['cycle2'].isin([j])]\n",
    "        exp_counts_sum = sum(disynthon_table[exp_col_name])\n",
    "        beads_counts_sum = sum(disynthon_table[beads_col_name])\n",
    "        disynthon_exp_counts.append(exp_counts_sum)\n",
    "        disynthon_bead_counts.append(beads_counts_sum)\n",
    "        \n",
    "    disynthon_exp_counts = np.array(disynthon_exp_counts)\n",
    "    disynthon_bead_counts = np.array(disynthon_bead_counts)\n",
    "        \n",
    "    return disynthon_exp_counts, disynthon_bead_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_preds(model):\n",
    "    avg_preds = []\n",
    "    for i in range(len(cpd_indices)):\n",
    "        test_enrichments = model.predict_on_x(\n",
    "                x[cpd_indices[i], :], batch_size=BATCH_SIZE, device=DEVICE,\n",
    "            )\n",
    "        avg_preds.append(sum(test_enrichments) / len(test_enrichments))\n",
    "        \n",
    "    avg_preds = np.array(avg_preds)\n",
    "        \n",
    "    return avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_predicted_enrichments_vs_true(model, out='', x_ub=None, legend_loc=None):\n",
    "    R, R_lb, R_ub = R_ranges(disynthon_bead_counts, bead_tot[0], \n",
    "                             disynthon_exp_counts, exp_tot[0])\n",
    "    \n",
    "    fig = plt.figure(figsize=(3.33, 2), dpi=300) \n",
    "\n",
    "    lower_error = R - R_lb\n",
    "    upper_error = R_ub - R\n",
    "    error = [lower_error, upper_error]\n",
    "    container = plt.errorbar(\n",
    "        x=R, \n",
    "        y=avg_preds,\n",
    "        xerr=error,\n",
    "        color='#1f77b4', # blue\n",
    "        label='disynthon',\n",
    "        marker='o',\n",
    "        markersize=3, \n",
    "        elinewidth=0.75,\n",
    "        ls='none',\n",
    "        ecolor='k',\n",
    "        capsize=1,\n",
    "        capthick=0.75, \n",
    "        zorder=2,\n",
    "    ) \n",
    "    \n",
    "    lines = plt.plot(\n",
    "        np.linspace(min(avg_preds), max(avg_preds), 100),\n",
    "        np.linspace(min(avg_preds), max(avg_preds), 100),\n",
    "        color='#2ca02c', # green\n",
    "        label='parity',\n",
    "        linewidth=0.75, \n",
    "        zorder=3,\n",
    "    )\n",
    "    \n",
    "    if legend_loc:\n",
    "        plt.legend(fontsize=7, loc=legend_loc)\n",
    "    else:\n",
    "        plt.legend(fontsize=7)\n",
    "        \n",
    "    fig.canvas.draw()\n",
    "    ax = plt.gca() \n",
    "    ax.tick_params(labelsize=8)\n",
    "    if x_ub:\n",
    "        ax.set_xlim([0, x_ub])\n",
    "        \n",
    "    ax.grid(zorder=1)\n",
    "    ax.set_xlabel('calculated enrichment', fontsize=8)\n",
    "    ax.set_ylabel('predicted enrichment', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(pathify(str(out)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (DD1S CAIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv(os.path.join(DELQSAR_ROOT, 'experiments', 'datasets', 'DD1S_CAIX_QSAR.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"HDF5_USE_FILE_LOCKING\"] = 'FALSE'\n",
    "# hf = h5py.File(os.path.join(DELQSAR_ROOT, 'experiments', DD1S_FINGERPRINTS_FILENAME), 'r')\n",
    "# x = np.array(hf['all_fps'])\n",
    "# INPUT_SIZE = x.shape[1]\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isdir('CAIX_disynthon_plots'):\n",
    "#     os.mkdir('CAIX_disynthon_plots')\n",
    "# def pathify(fname):\n",
    "#     return os.path.join('CAIX_disynthon_plots', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_counts = np.array(df_data[['exp_tot']], dtype='int')\n",
    "# bead_counts = np.array(df_data[['beads_tot']], dtype='int')\n",
    "# exp_tot = np.sum(exp_counts, axis=0) # column sums\n",
    "# bead_tot = np.sum(bead_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAIX random split model\n",
    "# BATCH_SIZE = 1024\n",
    "# LAYER_SIZES = [64, 64, 64]\n",
    "# DROPOUT = 0.1\n",
    "# model_CAIX = models.MLP(INPUT_SIZE, [int(size) for size in LAYER_SIZES],\n",
    "#                     dropout=DROPOUT, torch_seed=SEED)\n",
    "# model_CAIX.load_state_dict(torch.load(CAIX_RANDOM_SPLIT_MODEL_PATH))\n",
    "# print(str(model_CAIX))\n",
    "# if DEVICE:\n",
    "#     model_CAIX = model_CAIX.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpd_indices = get_cpd_indices(8, 114, 119)\n",
    "# np.save('DD1S_disynthon_cpd_indices.npy', cpd_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cpd_indices = np.load('DD1S_disynthon_cpd_indices.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disynthon_exp_counts, disynthon_bead_counts = get_counts_for_disynthons(8, 114, 119, 'exp_tot', 'beads_tot')\n",
    "# np.save('DD1S_CAIX_disynthon_exp_counts.npy', disynthon_exp_counts)\n",
    "# np.save('DD1S_CAIX_disynthon_bead_counts.npy', disynthon_bead_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## disynthon_exp_counts = np.load('DD1S_CAIX_disynthon_exp_counts.npy')\n",
    "## disynthon_bead_counts = np.load('DD1S_CAIX_disynthon_bead_counts.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_preds = get_avg_preds(model_CAIX)\n",
    "# np.save('DD1S_CAIX_disynthon_avg_preds.npy', avg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## avg_preds = np.load('DD1S_CAIX_disynthon_avg_preds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_predicted_enrichments_vs_true(model_CAIX, out='DD1S_CAIX_disynthon_parity_plot', legend_loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triazine sEH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(os.path.join(DELQSAR_ROOT, 'experiments', 'datasets', 'triazine_lib_sEH_SIRT2_QSAR.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = 'FALSE'\n",
    "hf = h5py.File(os.path.join(DELQSAR_ROOT, 'experiments', triazine_FINGERPRINTS_FILENAME), 'r')\n",
    "x = np.array(hf['all_fps'])\n",
    "INPUT_SIZE = x.shape[1]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('sEH_disynthon_plots'):\n",
    "    os.mkdir('sEH_disynthon_plots')\n",
    "def pathify(fname):\n",
    "    return os.path.join('sEH_disynthon_plots', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts = np.array(df_data[['sEH [strep]_tot']], dtype='int')\n",
    "bead_counts = np.array(df_data[['beads-linker-only [strep]_tot']], dtype='int')\n",
    "exp_tot = np.sum(exp_counts, axis=0) # column sums\n",
    "bead_tot = np.sum(bead_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sEH random split model\n",
    "BATCH_SIZE = 1024\n",
    "LAYER_SIZES = [256, 128, 64]\n",
    "DROPOUT = 0.4\n",
    "model_sEH = models.MLP(INPUT_SIZE, [int(size) for size in LAYER_SIZES],\n",
    "                    dropout=DROPOUT, torch_seed=SEED)\n",
    "model_sEH.load_state_dict(torch.load(sEH_RANDOM_SPLIT_MODEL_PATH))\n",
    "print(str(model_sEH))\n",
    "if DEVICE:\n",
    "    model_sEH = model_sEH.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_indices = get_cpd_indices(78, 290, 250)\n",
    "np.save('triazine_disynthon_cpd_indices.npy', cpd_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpd_indices = np.load('triazine_disynthon_cpd_indices.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disynthon_exp_counts, disynthon_bead_counts = get_counts_for_disynthons(78, 290, 250, \n",
    "                                                                        'sEH [strep]_tot', \n",
    "                                                                        'beads-linker-only [strep]_tot')\n",
    "np.save('sEH_disynthon_exp_counts.npy', disynthon_exp_counts)\n",
    "np.save('sEH_disynthon_bead_counts.npy', disynthon_bead_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disynthon_exp_counts = np.load('sEH_disynthon_exp_counts.npy')\n",
    "# disynthon_bead_counts = np.load('sEH_disynthon_bead_counts.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = get_avg_preds(model_sEH)\n",
    "np.save('sEH_disynthon_avg_preds.npy', avg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_preds = np.load('sEH_disynthon_avg_preds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predicted_enrichments_vs_true(model_sEH, out='sEH_disynthon_parity_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predicted_enrichments_vs_true(model_sEH, out='sEH_disynthon_parity_plot_zoom_in_800', x_ub=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triazine SIRT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(os.path.join(DELQSAR_ROOT, 'experiments', 'datasets', 'triazine_lib_sEH_SIRT2_QSAR.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = 'FALSE'\n",
    "hf = h5py.File(os.path.join(DELQSAR_ROOT, 'experiments', triazine_FINGERPRINTS_FILENAME), 'r')\n",
    "x = np.array(hf['all_fps'])\n",
    "INPUT_SIZE = x.shape[1]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('SIRT2_disynthon_plots'):\n",
    "    os.mkdir('SIRT2_disynthon_plots')\n",
    "def pathify(fname):\n",
    "    return os.path.join('SIRT2_disynthon_plots', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_counts = np.array(df_data[['SIRT2 [strep]_tot']], dtype='int')\n",
    "bead_counts = np.array(df_data[['beads-linker-only [strep]_tot']], dtype='int')\n",
    "exp_tot = np.sum(exp_counts, axis=0) # column sums\n",
    "bead_tot = np.sum(bead_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIRT2 random split model\n",
    "BATCH_SIZE = 1024\n",
    "LAYER_SIZES = [256, 128, 64]\n",
    "DROPOUT = 0.1\n",
    "model_SIRT2 = models.MLP(INPUT_SIZE, [int(size) for size in LAYER_SIZES],\n",
    "                    dropout=DROPOUT, torch_seed=SEED)\n",
    "model_SIRT2.load_state_dict(torch.load(SIRT2_RANDOM_SPLIT_MODEL_PATH))\n",
    "print(str(model_SIRT2))\n",
    "if DEVICE:\n",
    "    model_SIRT2 = model_SIRT2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_indices = get_cpd_indices(78, 290, 250) \n",
    "np.save('triazine_disynthon_cpd_indices.npy', cpd_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpd_indices = np.load('triazine_disynthon_cpd_indices.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = get_avg_preds(model_SIRT2)\n",
    "np.save('SIRT2_disynthon_avg_preds.npy', avg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_preds = np.load('SIRT2_disynthon_avg_preds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disynthon_exp_counts, disynthon_bead_counts = get_counts_for_disynthons(78, 290, 250, \n",
    "                                                                        'SIRT2 [strep]_tot', \n",
    "                                                                        'beads-linker-only [strep]_tot')\n",
    "np.save('SIRT2_disynthon_exp_counts.npy', disynthon_exp_counts)\n",
    "np.save('SIRT2_disynthon_bead_counts.npy', disynthon_bead_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disynthon_exp_counts = np.load('SIRT2_disynthon_exp_counts.npy')\n",
    "# disynthon_bead_counts = np.load('SIRT2_disynthon_bead_counts.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predicted_enrichments_vs_true(model_SIRT2, out='SIRT2_disynthon_parity_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predicted_enrichments_vs_true(model_SIRT2, out='SIRT2_disynthon_parity_plot_zoom_in_100', x_ub=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_predicted_enrichments_vs_true(model_SIRT2, out='SIRT2_disynthon_parity_plot_zoom_in_50', x_ub=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "chemprop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
